## 1. In a pipeline RISC processor, and individual instruction does not execute in fewer clock cycles. How is it the possible that complete program take fewer clock cycles with pipelining than without? If we have _N_ pipeline stages, will all programs become _N_ times faster? Why or why not?
### Answer:
Because with a pipeline multiple stages of the instruction execution can be done by step by step, and since a part of the CPU is avialable after each step a new instruction can put in the pipeline, leading to a theoretical speed up of N. However this is not true for all programs, since there can occur dependences between instructions that can lead to pipeline stalls.

## 2. In a superscalar processor speculative execution is very important. What is it, why can it make execution faster, and how is chaos prevented (for instance, that a register or memory location is modifed only if it should be)?
### Answer:
Superscalar processors can execute several hundered instructions every clock cycle. Which increases the likelyhood that it encounters a branch (such as a if-statement in the source code) having to wait for this branch to be evaluated would halt the execution substantially. However using speculative execution it simply executes the most likely outcome of the branch using **branch prediction**. Branch prediction uses a hardware data structure, called the branch prediction table, that remembers the result of previous jumps at that instruction and updates during execution. Superscalar processors also need a **reorder buffer**. The reorder buffer is a simple FIFO queue that loads instructions and executes the oldest instruction first, if a branch prediction was incorrect all the instructions in the queue can be removed. Since it would be disastorous for a instruction to write to memory or register a speculative instructions cannot execute these changes.**Rename registers** can remedy this a long side with output and anti dependencies. When a instruction wishes to write to a register it instead gets assigned a rename register where it writes its value instead. When a following instruction wishes to read from the register that the previous instruction wrote to it instead reads from the previously assigned rename register. If the instruction that wrote to rename registers executes without being killed it can then later change the real register.

## 3. What is the purpose of having sets in a cache?
### Answer:
To be able to have multiple places to place the data in case two or more variable in use at the same time are overwriting the same cache line/lbock, without having an expensive fully associative cache.

### Why are caches not "simplified" to having only one set?
#### Answer:
Because the hardware cost of having many comparators would be very expensive and take up a lot of space on the chip which could be used for other, more clever, things.

### Suppose a cache is divided into sets where each set contains four cache blocks. What is such a cache called?
#### Answer:
4-way set associative cache.
### With the same cache as above, can the data at a memory address _A_ be put in any set? Why or why not?
#### Answer:
No since there is function, which works like a hash function, which maps the address to a specific set.
### In any of the cache blocks? Why or why not?
#### Answer:
Yes where there is available space. That's why we have four comparators.
### What is meant by cache levels?
#### Answer:
The different levels vary in size (L1 small and fast, L2 bigger slower, L3 even more so) and composition and the L1 cache contains the most recently used data/addresses. The data in level _i_ is a subset of that in level _i + 1_.

### What could be the reason be for having separate first level caches for data and instructions?
#### Answer:
To access the concurrently and not mix instructions and data to not make the compete for space in the cache.

## 5. Suppose you wish to understand why one implementation of an algorithm is faster than another when executed on a particular machine. How can the following tools be useful:
+ cachegrind
+ gcov
+ gprof
+ OProfile
+ A pipeline level simulator such as IBM's clock cycle true simulators for different implemnations of Power processor?

### Answer:
+ cachegrind - Profiler used to check the cache performance of the caches, and see how many cache misses occur in the program.
+ gcov - Profiler used to see the coverage of functions and lines. See how many times each is run, if it all.
+ gprof - Profiler that generates call graphs for the functions, see how often and where from each function is called.
+ OProfile - A multitool profiler to analyze different events generate at kernel level, for example how large amount of the clock cycles are done on each line of the source code, can see which instructions are expensive.
+ Pipeline simulator - Control which instructions give large pipeline stalls.


